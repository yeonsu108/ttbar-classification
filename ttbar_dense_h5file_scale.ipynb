{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb844ca6-bd5b-4117-93b2-1edd3ca2b43e",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to build and train a convolutional network in NengoDL, and then deploy that network on Loihi.\n",
    "\n",
    "We will assume here that the reader is somewhat familiar with NengoDL, and focus on the issue of how to use NengoDL to train a network for Loihi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f136008-0b4d-4ce6-b9f2-3694c96abef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 15:59:57.490697: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-24 16:00:00.820399: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import uproot\n",
    "from myutils import *\n",
    "\n",
    "try:\n",
    "    import requests\n",
    "\n",
    "    has_requests = True\n",
    "except ImportError:\n",
    "    has_requests = False\n",
    "\n",
    "import nengo_loihi\n",
    "\n",
    "epoch = 30\n",
    "scale = 10\n",
    "train_outdir = \"./SNN0425_\"+str(epoch)+\"_scale\"+str(scale)\n",
    "os.makedirs(train_outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d69da0-95a4-4674-9624-03c2d26be752",
   "metadata": {},
   "source": [
    "We'll define helper function for drawing SNN results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1413c2-29b1-4095-9805-1b9199b69448",
   "metadata": {},
   "source": [
    "We’ll use the tth(bb) and ttbb data to demonstrate the steps. The samples are generated by MADGRAPH@aMC_NLO with DELPHES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e7857a-01e1-410c-8683-ffa71488c9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        category  njets  nbjets  ncjets  nElectron  nMuon  nLepton  \\\n",
      "0              1      5       4       1          0      1        1   \n",
      "1              3      9       2       2          1      0        1   \n",
      "2              2      4       2       0          1      0        1   \n",
      "3              4      7       3       1          1      0        1   \n",
      "4              2      6       3       0          1      0        1   \n",
      "...          ...    ...     ...     ...        ...    ...      ...   \n",
      "382520         2      6       3       0          0      1        1   \n",
      "382521         0      6       4       1          1      0        1   \n",
      "382522         1      8       4       2          1      0        1   \n",
      "382523         0      4       4       0          1      0        1   \n",
      "382524         1      4       2       0          1      0        1   \n",
      "\n",
      "          bjet1_pt    bjet2_pt  bjet1_eta  ...   Wlb1Eta   Wlb2Eta   Wlb1Phi  \\\n",
      "0       118.250000  116.328125   0.293274  ...  0.347168  0.350647 -1.378906   \n",
      "1       223.656250   36.843750  -1.009521  ... -0.539551  0.152130  0.975464   \n",
      "2        77.015625   64.203125  -0.943359  ... -1.447021  0.040489 -1.654053   \n",
      "3       141.343750   45.632812  -1.764404  ... -0.794067 -0.975586  1.499756   \n",
      "4       164.656250   90.187500   1.091309  ... -1.367676 -2.443359  2.495605   \n",
      "...            ...         ...        ...  ...       ...       ...       ...   \n",
      "382520  137.562500   50.421875   2.317871  ...  1.547363  1.890625  0.947510   \n",
      "382521  120.812500   86.234375  -0.898315  ... -2.877441 -1.646729 -1.048584   \n",
      "382522   88.156250   68.046875  -0.111526  ... -0.054359  1.402344  0.143494   \n",
      "382523   79.562500   75.828125   1.528564  ...  2.113281  1.727051 -1.239502   \n",
      "382524   52.546875   40.906250  -1.386963  ...  0.221252  1.027588  2.342773   \n",
      "\n",
      "         Wlb2Phi    Wlb1Mass   Wlb2Mass     Wlb1Ht      Wlb2Ht     Wlb1Mt  \\\n",
      "0      -1.650146  320.875000  247.93750  312.62500  257.687500  343.25000   \n",
      "1       1.621582  706.500000  345.68750  607.00000  420.125000  760.62500   \n",
      "2       0.847656  176.843750  266.00000  134.15625  121.343750  197.93750   \n",
      "3       1.582520  136.125000  163.28125  171.71875  168.906250  205.25000   \n",
      "4       0.829346  218.656250  277.06250   94.12500   63.984375  238.03125   \n",
      "...          ...         ...        ...        ...         ...        ...   \n",
      "382520  0.949097  184.218750  198.90625  171.50000  166.937500  227.65625   \n",
      "382521 -2.228516  267.812500  224.59375  253.81250  198.718750  268.43750   \n",
      "382522  0.015972  121.109375  221.75000  191.90625  159.062500  211.93750   \n",
      "382523 -2.879883  194.562500  177.06250  156.25000  126.453125  200.65625   \n",
      "382524  2.530762  316.000000  228.93750  215.59375  203.968750  367.75000   \n",
      "\n",
      "           Wlb2Mt  \n",
      "0       305.37500  \n",
      "1       490.56250  \n",
      "2       268.31250  \n",
      "3       204.28125  \n",
      "4       283.31250  \n",
      "...           ...  \n",
      "382520  225.34375  \n",
      "382521  237.84375  \n",
      "382522  232.93750  \n",
      "382523  182.43750  \n",
      "382524  260.18750  \n",
      "\n",
      "[382525 rows x 152 columns]\n",
      "Index(['category', 'njets', 'nbjets', 'ncjets', 'nElectron', 'nMuon',\n",
      "       'nLepton', 'bjet1_pt', 'bjet2_pt', 'bjet1_eta',\n",
      "       ...\n",
      "       'Wlb1Eta', 'Wlb2Eta', 'Wlb1Phi', 'Wlb2Phi', 'Wlb1Mass', 'Wlb2Mass',\n",
      "       'Wlb1Ht', 'Wlb2Ht', 'Wlb1Mt', 'Wlb2Mt'],\n",
      "      dtype='object', length=152)\n",
      "[1 3 2 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# set up training data\n",
    "variables = [\n",
    "    'njets', 'nbjets', 'ncjets', 'nElectron', 'nMuon', 'MET_met', 'HT', # 'nLepton', 'MET_px', 'MET_py',\n",
    "    'Lepton_pt', 'Lepton_eta', 'Lepton_e',# 'Lepton_phi',\n",
    "    'Jet1_pt', 'Jet1_eta', 'Jet1_e', 'Jet1_btag', 'Jet2_pt', 'Jet2_eta', 'Jet2_e', 'Jet2_btag',# 'Jet_phi1', 'Jet_phi2',\n",
    "    'Jet3_pt', 'Jet3_eta', 'Jet3_e', 'Jet3_btag', 'Jet4_pt', 'Jet4_eta', 'Jet4_e', 'Jet4_btag',# 'Jet_phi3', 'Jet_phi4',\n",
    "    #'bjet1_pt', 'bjet1_eta', 'bjet1_e', 'bjet2_pt', 'bjet2_eta', 'bjet2_e',# 'bjet1_phi', 'bjet2_phi',\n",
    "    'selbjet1_pt', 'selbjet1_eta', 'selbjet1_e', 'selbjet2_pt', 'selbjet2_eta', 'selbjet2_e',# 'selbjet1_phi', 'selbjet2_phi',\n",
    "\n",
    "    'bbdR',   'bbdEta',   'bbdPhi',   'bbPt',   'bbEta',   'bbMass',   'bbHt',   'bbMt',  # 'bbPhi',\n",
    "    'nub1dR', 'nub1dEta', 'nub1dPhi', 'nub1Pt', 'nub1Eta', 'nub1Mass', 'nub1Ht', 'nub1Mt',# 'nub1Phi',\n",
    "    'nub2dR', 'nub2dEta', 'nub2dPhi', 'nub2Pt', 'nub2Eta', 'nub2Mass', 'nub2Ht', 'nub2Mt',# 'nub2Phi',\n",
    "    'nubbdR', 'nubbdEta', 'nubbdPhi', 'nubbPt', 'nubbEta', 'nubbMass', 'nubbHt', 'nubbMt',# 'nubbPhi',\n",
    "    'lb1dR',  'lb1dEta',  'lb1dPhi',  'lb1Pt',  'lb1Eta',  'lb1Mass',  'lb1Ht',  'lb1Mt', # 'lb1Phi',\n",
    "    'lb2dR',  'lb2dEta',  'lb2dPhi',  'lb2Pt',  'lb2Eta',  'lb2Mass',  'lb2Ht',  'lb2Mt', # 'lb2Phi',\n",
    "    'lbbdR',  'lbbdEta',  'lbbdPhi',  'lbbPt',  'lbbEta',  'lbbMass',  'lbbHt',  'lbbMt', # 'lbbPhi',\n",
    "    'Wjb1dR', 'Wjb1dEta', 'Wjb1dPhi', 'Wjb1Pt', 'Wjb1Eta', 'Wjb1Mass', 'Wjb1Ht', 'Wjb1Mt',# 'Wjb1Phi',\n",
    "    'Wjb2dR', 'Wjb2dEta', 'Wjb2dPhi', 'Wjb2Pt', 'Wjb2Eta', 'Wjb2Mass', 'Wjb2Ht', 'Wjb2Mt',# 'Wjb2Phi',\n",
    "    'Wlb1dR', 'Wlb1dEta', 'Wlb1dPhi', 'Wlb1Pt', 'Wlb1Eta', 'Wlb1Mass', 'Wlb1Ht', 'Wlb1Mt',# 'Wlb1Phi',\n",
    "    'Wlb2dR', 'Wlb2dEta', 'Wlb2dPhi', 'Wlb2Pt', 'Wlb2Eta', 'Wlb2Mass', 'Wlb2Ht', 'Wlb2Mt',# 'Wlb2Phi',\n",
    " \n",
    "]\n",
    "class_names = [\"tthbb\", \"ttbb\", \"ttbj\", \"ttcc\", \"ttlf\"]\n",
    "nClass, nVariables = len(class_names), len(variables)\n",
    "\n",
    "pd_data = pd.read_hdf('samples/data.h5', key='df', mode='r')\n",
    "print (pd_data)\n",
    "print (pd_data.columns)\n",
    "\n",
    "train_data = pd_data.filter(items = variables)\n",
    "train_data = (train_data - train_data.min())*scale/(train_data.max() - train_data.min())\n",
    "train_data = np.array(train_data).astype(float)\n",
    "train_out = np.array(pd_data.filter(items = [\"category\"])).reshape((len(pd_data),))\n",
    "\n",
    "print (train_out)\n",
    "\n",
    "trainlen = 267767\n",
    "train_images = train_data[:trainlen, 0::]\n",
    "train_labels = train_out[:trainlen]\n",
    "test_images = train_data[trainlen:, 0::]\n",
    "test_labels = train_out[trainlen:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d141754e-26dd-4ff5-b647-737bf688f2f9",
   "metadata": {},
   "source": [
    "Next we define the structure of our network. Because we need to keep the number of neurons and axons per core below the Loihi hardware limits, we adopt a somewhat unusual network architecture. We’ll have a relatively small core network, so that each layer fits on one Loihi core, and then repeat that network several times in parallel, summing their output. We can think of this as a variation on ensemble learning. See the CIFAR-10 example for a different approach that uses NengoLoihi’s BlockShape functionality to automatically split larger layers across cores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14caccd6-49bc-4210-9802-29295307beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.001  # simulation timestep\n",
    "presentation_time = 0.1  # input presentation time\n",
    "max_rate = 120  # neuron firing rates\n",
    "# neuron spike amplitude (scaled so that the overall output is ~1)\n",
    "amp = 1 / max_rate\n",
    "\n",
    "with nengo.Network(seed=0) as net:\n",
    "    # set up the default parameters for ensembles/connections\n",
    "    nengo_loihi.add_params(net)\n",
    "    net.config[nengo.Ensemble].max_rates = nengo.dists.Choice([max_rate])\n",
    "    net.config[nengo.Ensemble].intercepts = nengo.dists.Choice([0])\n",
    "    net.config[nengo.Connection].synapse = None\n",
    "    \n",
    "    #net.config[nengo.Ensemble].neuron_type = nengo.SpikingRectifiedLinear(amplitude=amp)\n",
    "    neuron_type = nengo.LIF(tau_rc=0.02, tau_ref=0.001, amplitude=amp)\n",
    "    #neuron_type = nengo.SpikingRectifiedLinear(amplitude=amp)\n",
    "    net.config[nengo.Ensemble].neuron_type = nengo.LIF(tau_rc=0.02, tau_ref=0.001, amplitude=amp)\n",
    "    \n",
    "    # the input node that will be used to feed in input images\n",
    "    inp = nengo.Node(\n",
    "        nengo.processes.PresentInput(test_images, presentation_time), size_out=nVariables\n",
    "    )\n",
    "\n",
    "    # the output node provides the 2-dimensional classification\n",
    "    out = nengo.Node(size_in=nClass)\n",
    "\n",
    "    layer_1 = nengo.Ensemble(n_neurons=nVariables, dimensions=1, neuron_type=neuron_type, label=\"Layer 1\")\n",
    "    # first layer is off-chip to translate the images into spikes\n",
    "    net.config[layer_1].on_chip = False\n",
    "    nengo.Connection(inp, layer_1.neurons, transform=nengo_dl.dists.Glorot())\n",
    "\n",
    "    layer_2 = nengo.Ensemble(n_neurons=256, dimensions=1, neuron_type=neuron_type, label=\"Layer 2\")\n",
    "    nengo.Connection(layer_1.neurons, layer_2.neurons, transform=nengo_dl.dists.Glorot())\n",
    "\n",
    "    layer_3 = nengo.Ensemble(n_neurons=256, dimensions=1, neuron_type=neuron_type, label=\"Layer 3\")\n",
    "    nengo.Connection(layer_2.neurons, layer_3.neurons, transform=nengo_dl.dists.Glorot())\n",
    "\n",
    "    nengo.Connection(layer_3.neurons, out, transform=nengo_dl.dists.Glorot())\n",
    "\n",
    "    out_p = nengo.Probe(out, label=\"out_p\")\n",
    "    out_p_filt = nengo.Probe(out, synapse=nengo.Alpha(0.01), label=\"out_p_filt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3355b64-e591-4ee6-830b-c29e6c10a5e6",
   "metadata": {},
   "source": [
    "The next step is to optimize the parameters of the network using NengoDL.\n",
    "\n",
    "First we set up the input/target data for the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e2fd5d-fa2e-4ac1-8a98-e9a1a399d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training data, adding the time dimension (with size 1)\n",
    "minibatch_size = 200\n",
    "train_images = train_images[:, None, :]\n",
    "train_labels = train_labels[:, None, None]\n",
    "\n",
    "# for the test data evaluation we'll be running the network over time\n",
    "# using spiking neurons, so we need to repeat the input/target data\n",
    "# for a number of timesteps (based on the presentation_time)\n",
    "n_steps = int(presentation_time / dt)\n",
    "test_images = np.tile(test_images[:, None, :], (1, n_steps, 1))\n",
    "test_labels = np.tile(test_labels[:, None, None], (1, n_steps, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2775ae-7310-42f8-ad5c-01f6906bb807",
   "metadata": {},
   "source": [
    "Next we need to define our error functions.\n",
    "\n",
    "For training we will use the standard categorical cross-entropy loss function.\n",
    "\n",
    "For evaluation we will use classification accuracy (the % of images classified correctly) as an intuitive measure of how well the network is doing. Since we will be running the network over time during evaluation, we modify the loss function slightly so that it only assesses the accuracy on the last timestep.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82ed605-62b6-4297-9c2c-ec6f9f3b4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(y_true, y_pred):\n",
    "    return 100 * tf.metrics.sparse_categorical_accuracy(y_true[:, -1], y_pred[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052c44b-17c6-4f2d-a9fa-4281fa3c57cc",
   "metadata": {},
   "source": [
    "\n",
    "Now we create the NengoDL simulator and run the training using the sim.fit function.\n",
    "\n",
    "More details on how to use NengoDL to optimize a model can be found here: https://www.nengo.ai/nengo-dl/user-guide.html.\n",
    "\n",
    "To speed up this example we can set do_training=False to load some pre-trained parameters. \n",
    "\n",
    "Note that in order to run do_training=True, you will need to have TensorFlow installed with GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c01fd7-ddff-4f96-a577-4220f50d7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/yeonsuryou/miniconda3/envs/23snn/lib/python3.8/site-packages/nengo_dl/simulator.py:456: UserWarning: No GPU support detected. See https://www.nengo.ai/nengo-dl/installation.html#installing-tensorflow for instructions on setting up TensorFlow with GPU support.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construction finished in 0:00:00                                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/yeonsuryou/miniconda3/envs/23snn/lib/python3.8/site-packages/nengo_dl/simulator.py:1892: UserWarning: Number of elements in input data (114758) is not evenly divisible by Simulator.minibatch_size (200); input data will be truncated.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:00:16.253428: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5500800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before training: 19.95%finished in 0:00:00                            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/yeonsuryou/miniconda3/envs/23snn/lib/python3.8/site-packages/nengo_dl/simulator.py:1892: UserWarning: Number of elements in input data (267767) is not evenly divisible by Simulator.minibatch_size (200); input data will be truncated.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1338/1338 [==============================] - 25s 16ms/step - loss: 1.5413 - out_p_loss: 1.5413 - out_p_classification_accuracy: 30.4484\n",
      "Epoch 2/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.5093 - out_p_loss: 1.5093 - out_p_classification_accuracy: 33.0265\n",
      "Epoch 3/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.5015 - out_p_loss: 1.5015 - out_p_classification_accuracy: 33.5486\n",
      "Epoch 4/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4982 - out_p_loss: 1.4982 - out_p_classification_accuracy: 33.7444\n",
      "Epoch 5/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4949 - out_p_loss: 1.4949 - out_p_classification_accuracy: 34.1487\n",
      "Epoch 6/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4946 - out_p_loss: 1.4946 - out_p_classification_accuracy: 34.1166\n",
      "Epoch 7/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4925 - out_p_loss: 1.4925 - out_p_classification_accuracy: 34.2018\n",
      "Epoch 8/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4918 - out_p_loss: 1.4918 - out_p_classification_accuracy: 34.3984\n",
      "Epoch 9/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4914 - out_p_loss: 1.4914 - out_p_classification_accuracy: 34.2840\n",
      "Epoch 10/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4901 - out_p_loss: 1.4901 - out_p_classification_accuracy: 34.3277\n",
      "Epoch 11/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4893 - out_p_loss: 1.4893 - out_p_classification_accuracy: 34.4484\n",
      "Epoch 12/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4884 - out_p_loss: 1.4884 - out_p_classification_accuracy: 34.5721\n",
      "Epoch 13/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4885 - out_p_loss: 1.4885 - out_p_classification_accuracy: 34.4522\n",
      "Epoch 14/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4879 - out_p_loss: 1.4879 - out_p_classification_accuracy: 34.5684\n",
      "Epoch 15/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4875 - out_p_loss: 1.4875 - out_p_classification_accuracy: 34.5680\n",
      "Epoch 16/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4870 - out_p_loss: 1.4870 - out_p_classification_accuracy: 34.6289\n",
      "Epoch 17/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4867 - out_p_loss: 1.4867 - out_p_classification_accuracy: 34.6114\n",
      "Epoch 18/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4869 - out_p_loss: 1.4869 - out_p_classification_accuracy: 34.5953\n",
      "Epoch 19/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4857 - out_p_loss: 1.4857 - out_p_classification_accuracy: 34.7201\n",
      "Epoch 20/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4851 - out_p_loss: 1.4851 - out_p_classification_accuracy: 34.7552\n",
      "Epoch 21/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4851 - out_p_loss: 1.4851 - out_p_classification_accuracy: 34.7429\n",
      "Epoch 22/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4846 - out_p_loss: 1.4846 - out_p_classification_accuracy: 34.6584\n",
      "Epoch 23/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4845 - out_p_loss: 1.4845 - out_p_classification_accuracy: 34.7362\n",
      "Epoch 24/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4838 - out_p_loss: 1.4838 - out_p_classification_accuracy: 34.8505\n",
      "Epoch 25/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4825 - out_p_loss: 1.4825 - out_p_classification_accuracy: 34.8793\n",
      "Epoch 26/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4821 - out_p_loss: 1.4821 - out_p_classification_accuracy: 34.8942\n",
      "Epoch 27/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4822 - out_p_loss: 1.4822 - out_p_classification_accuracy: 34.9118\n",
      "Epoch 28/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4818 - out_p_loss: 1.4818 - out_p_classification_accuracy: 34.9978\n",
      "Epoch 29/30\n",
      "1338/1338 [==============================] - 20s 15ms/step - loss: 1.4807 - out_p_loss: 1.4807 - out_p_classification_accuracy: 35.1073\n",
      "Epoch 30/30\n",
      "1338/1338 [==============================] - 21s 16ms/step - loss: 1.4806 - out_p_loss: 1.4806 - out_p_classification_accuracy: 35.0744\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:17:25.264209: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5500800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:23:54.878982: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5500800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy after training: 35.38%\n"
     ]
    }
   ],
   "source": [
    "do_training = True\n",
    "\n",
    "with nengo_dl.Simulator(net, minibatch_size=minibatch_size, seed=0) as sim:\n",
    "    if do_training:\n",
    "        sim.compile(loss={out_p_filt: classification_accuracy})\n",
    "        print(\n",
    "            \"accuracy before training: %.2f%%\"\n",
    "            % sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"]\n",
    "        )\n",
    "\n",
    "        # run training\n",
    "        sim.compile(\n",
    "            optimizer=tf.optimizers.RMSprop(0.001),\n",
    "            loss={out_p: tf.losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    "            metrics={out_p: classification_accuracy},\n",
    "        )\n",
    "        sim.fit(train_images, {out_p: train_labels}, epochs=epoch)\n",
    "\n",
    "        sim.compile(loss={out_p_filt: classification_accuracy})\n",
    "        acc = \"%.2f%%\" % sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"]\n",
    "        print(\n",
    "            \"accuracy after training: %.2f%%\"\n",
    "            % sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"]\n",
    "        )\n",
    "        sim.save_params(train_outdir+\"/ttbar_params\")\n",
    "    else:\n",
    "        sim.load_params(train_outdir+\"/ttbar_params\")\n",
    "\n",
    "    # store trained parameters back into the network\n",
    "    sim.freeze_params(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff5c26d-e8a1-43af-a06b-8463230030cd",
   "metadata": {},
   "source": [
    "As we built it, the network has no synaptic filters on the neural connections. This works well during training, but we can see that the error is still somewhat high when we evaluate it using spiking neurons. We can improve performance by adding synaptic filters to our trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f2cfc-5a47-4cc5-8758-5e4c364d0008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:31:24.550435: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5500800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    }
   ],
   "source": [
    "for conn in net.all_connections:\n",
    "    conn.synapse = 0.005\n",
    "\n",
    "if do_training:\n",
    "    with nengo_dl.Simulator(net, minibatch_size=minibatch_size) as sim:\n",
    "        sim.compile(loss={out_p_filt: classification_accuracy})\n",
    "        acc = \"%.2f%%\"  % sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"]\n",
    "        print(\n",
    "            \"accuracy w/ synapse: %.2f%%\"\n",
    "            % sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"]\n",
    "        )\n",
    "        sim.save_params(train_outdir+\"/ttbar_synapse\")\n",
    "\n",
    "        # pred_train = sim.predict(x=train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7912433-b333-4765-90d1-eb0d01c6c376",
   "metadata": {},
   "source": [
    "Now we can load our trained network, with synaptic filters, onto Loihi. This is as easy as passing the network to nengo_loihi.Simulator and running it, there is no extra work required. We will give the network 50 test images, and use that to evaluate the classification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d447806-afad-427c-949e-dfb8e5272b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_presentations = 2000\n",
    "\n",
    "# if running on Loihi, increase the max input spikes per step\n",
    "hw_opts = dict(snip_max_spikes_per_step=max_rate)\n",
    "with nengo_loihi.Simulator(\n",
    "    net,\n",
    "    dt=dt,\n",
    "    precompute=False,\n",
    "    hardware_options=hw_opts,\n",
    ") as sim:\n",
    "    # run the simulation on Loihi\n",
    "    sim.run(n_presentations * presentation_time)\n",
    "\n",
    "    # check classification accuracy\n",
    "    step = int(presentation_time / dt)\n",
    "    output = sim.data[out_p_filt][step - 1 :: step]\n",
    "\n",
    "    acc = 100 * np.mean(\n",
    "        np.argmax(output, axis=-1) == test_labels[:n_presentations, -1, 0]\n",
    "    )\n",
    "    print(\"loihi accuracy: %.2f%%\" % acc)\n",
    "\n",
    "    predicted = np.argmax(output, axis=-1)\n",
    "    correct = test_labels[:n_presentations, -1, 0]\n",
    "\n",
    "    predicted = np.array(predicted, dtype=int)\n",
    "    correct = np.array(correct, dtype=int)\n",
    "\n",
    "    print(\"Predicted labels:\\t\", predicted)\n",
    "    print(\"Correct labels: \\t\", correct)\n",
    "    print(\"loihi acc: %.2f%%\" % acc)\n",
    "\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(correct, predicted, classes=class_names, \n",
    "                          savename=train_outdir+\"/loihi_confusion_matrix_val.pdf\")\n",
    "    plot_confusion_matrix(correct, predicted, classes=class_names, normalize=True, \n",
    "                          savename=train_outdir+\"/loihi_norm_confusion_matrix_val.pdf\")\n",
    "    plot_confusion_matrix(correct, predicted, classes=class_names, normalize=True, \n",
    "                          savename=train_outdir+\"/loihi_norm_confusion_matrix_val.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3fe24-b248-4806-b59c-cf24a6cfc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e06d5f-65a4-419a-868f-7c00fe4746a5",
   "metadata": {},
   "source": [
    "We can also plot the output activity from the Loihi network as we show it different test images, to see what this performance looks like in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f630d-9e7d-469e-ba85-9414704f1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    n_plots = 5\n",
    "    correct = test_labels[n_plots*i:n_plots*(i+1), -1, 0]\n",
    "    print (correct)\n",
    "\n",
    "    correct_str = \"             \"\n",
    "    for j in correct:\n",
    "        correct_str += class_names[j] + \"           \"\n",
    "    correct = \"\".join(map(str, correct))\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    tmp_x, tmp_y = sim.trange()[n_plots*i*step:n_plots*(i+1)*step], tf.nn.softmax(sim.data[out_p_filt][n_plots*i*step:n_plots*(i+1)*step])\n",
    "    #print (tmp_x)\n",
    "    tmp_x = ((tmp_x*10)%5.00001)/10\n",
    "    #print (tmp_x)\n",
    "    #plt.plot(sim.trange()[n_plots*i*step:n_plots*(i+1)*step], tf.nn.softmax(sim.data[out_p_filt][n_plots*i*step:n_plots*(i+1)*step]))\n",
    "    plt.plot(tmp_x, tmp_y)\n",
    "    for j in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        plt.axvline(x=j, color='r', linestyle='--', linewidth=1)\n",
    "    plt.legend(class_names)#, loc=\"upper left\", bbox_to_anchor=(1.2, 0.99))\n",
    "    plt.xlabel(\"time [s]\")\n",
    "    plt.ylabel(\"probability\")\n",
    "    plt.title(correct_str)\n",
    "\n",
    "    plt.savefig(train_outdir+\"/label_\"+correct+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9fad93-a4d0-47b7-bccb-4cb16510ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plots = 10\n",
    "plt.figure()\n",
    "\n",
    "print (test_labels[:n_plots, -1, 0])\n",
    "\n",
    "print (test_labels.shape)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(sim.trange()[: n_plots * step], sim.data[out_p][: n_plots * step])\n",
    "plt.legend([\"%d\" % i for i in range(10)], loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
